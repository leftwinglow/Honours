{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torchmetrics import MetricCollection, classification, wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules import Fingerprint_Generator\n",
    "\n",
    "fingerprint = \"ecfp-count\"\n",
    "\n",
    "# df = pd.read_csv(\"Transformed_Data/DILIst_DILI.csv\", index_col=0)  # Map style dataset\n",
    "# df = Fingerprint_Generator.generate_fp_column(df, df.drug, fp_type=fingerprint)\n",
    "\n",
    "# df_fp = pd.DataFrame(df.iloc[:, 2])\n",
    "# df_fp.insert(len(df_fp.columns), \"DILI?\", df.iloc[:, 1].astype(int))  # Insert 'DILI?' column as the last column\n",
    "\n",
    "# df_fp.to_csv(\"Transformed_Data/testo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                         ecfp-count\n",
      "0      0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1      0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "df = Fingerprint_Generator.generate_fp_column(df, df.smiles, fp_type=fingerprint)\n",
    "df = df.drop(\"smiles\", axis=1)\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DILIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels) -> None:\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features.iloc[index]\n",
    "        labels = self.labels.iloc[index]\n",
    "        return torch.tensor([features], dtype=torch.float32), torch.tensor([labels], dtype=torch.float32)\n",
    "        # return torch.from_numpy(np.asarray([features])), torch.from_numpy(np.asarray([labels]))\n",
    "\n",
    "\n",
    "# DILIfeatures = df_fp.iloc[:, 0]\n",
    "# DILIlabels = df_fp.iloc[:, 1]\n",
    "\n",
    "DILIfeatures = df.iloc[:, 1]\n",
    "DILIlabels = df.iloc[:, 0]\n",
    "\n",
    "dilidataset = DILIDataset(DILIfeatures, DILIlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split succeeded\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_size = int(len(dilidataset) * 0.8)\n",
    "validation_size = len(dilidataset) - train_size\n",
    "\n",
    "train_data, validation_data = torch.utils.data.random_split(dilidataset, [train_size, validation_size])\n",
    "\n",
    "if len(train_data) + len(validation_data) == len(dilidataset):\n",
    "    print(\"Dataset split succeeded\")\n",
    "else:\n",
    "    print(\"Dataset split failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from My_Pytorch_Utilities import reset_weights\n",
    "\n",
    "def reset_weights(model, verbose: bool = False) -> None:\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "            if verbose is False:\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Reset trainable parameters of layer = {layer}\")\n",
    "\n",
    "\n",
    "class DILI_Predictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_output = self.fc1(x)\n",
    "        model_output = torch.relu(model_output)\n",
    "        model_output = self.fc2(model_output)\n",
    "        model_output = torch.relu(model_output)\n",
    "        model_output = self.fc3(model_output)\n",
    "        model_output = self.sigmoid(model_output)\n",
    "        return model_output\n",
    "\n",
    "\n",
    "class DILI_Predictor_Sequential(nn.Sequential):\n",
    "    def __init__(self, input_size, hidden_size, output_size) -> None:\n",
    "        super().__init__(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "model0 = DILI_Predictor_Sequential(2048, 512, 1).to(device)\n",
    "\n",
    "# model0 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_collection = MetricCollection([\n",
    "    classification.Accuracy(task='binary', average='macro').to(device),\n",
    "    classification.BinaryAUROC().to(device),\n",
    "    classification.BinaryMatthewsCorrCoef().to(device)\n",
    "    ])\n",
    "\n",
    "b_acc = classification.Accuracy(task='binary', average='macro').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 smiles  label\n",
      "0                                     CN(C)C(=N)N=C(N)N      0\n",
      "1                                      COC(=O)C=CC(=O)O      0\n",
      "2                                     O=C(O)C=Cc1ccccc1      0\n",
      "3                                     Cc1ccc(C(C)C)cc1O      0\n",
      "4                                    COc1ccc(C(=O)O)cc1      0\n",
      "...                                                 ...    ...\n",
      "2339  COc1ccc(CCOC2OC(CO)C(OC(=O)C=Cc3ccc(O)c(OC)c3)...      0\n",
      "2340  COc1ccc(-c2oc3c(CC=C(C)C)c(OC4OC(CO)C(O)C(O)C4...      0\n",
      "2341  COC(=O)C12Oc3cc(C)c(-c4c(C)cc5c(c4O)C(O)=C4C(=...      0\n",
      "2342  CC1(C)CCC2(C(=O)O)CCC3(C)C(=CCC4C5(C)CC(O)C(OC...      0\n",
      "2343                       Oc1ccc(C=Cc2cc(O)cc(O)c2)cc1      0\n",
      "\n",
      "[2344 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\pytorch_DILI_CrossVal.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mTransformed_Data/rega_train.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m Fingerprint_Comparator\u001b[39m.\u001b[39mPytorch_Train(df\u001b[39m.\u001b[39miloc[:,\u001b[39m0\u001b[39m], df\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m], model0, \u001b[39m2048\u001b[39m, metric_collection)\u001b[39m.\u001b[39mregular_fingerprint([\u001b[39m\"\u001b[39m\u001b[39mecfp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mecfp-count\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\Modules\\Fingerprint_Comparator.py:194\u001b[0m, in \u001b[0;36mPytorch_Train.regular_fingerprint\u001b[1;34m(self, fingerprints)\u001b[0m\n\u001b[0;32m    188\u001b[0m     PyTorch_Dataset \u001b[39m=\u001b[39m PyTorch_Training\u001b[39m.\u001b[39mSMILES_Features_Dataset(fingerprint_features, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels)\n\u001b[0;32m    190\u001b[0m     \u001b[39m# dim_padding = torch.tensor(self.model_input_len) - fingerprint_features.size\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \n\u001b[0;32m    192\u001b[0m     \u001b[39m# fingerprint_features = torch.nn.functional.pad(fingerprint_features, (0, dim_padding))\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m     loss, score_df \u001b[39m=\u001b[39m PyTorch_Training\u001b[39m.\u001b[39mModel_Train_Test(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_collection)\u001b[39m.\u001b[39mtrain_model_crossval(PyTorch_Dataset)\n\u001b[0;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m score_df\n",
      "File \u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\Modules\\PyTorch_Training.py:94\u001b[0m, in \u001b[0;36mModel_Train_Test.train_model_crossval\u001b[1;34m(self, dataset, k_folds, epochs, batch_size, DP)\u001b[0m\n\u001b[0;32m     91\u001b[0m My_Pytorch_Utilities\u001b[39m.\u001b[39mTraining_Utilities()\u001b[39m.\u001b[39mreset_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)  \u001b[39m# Reset the model weights between each fold\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> 94\u001b[0m     train_loss, train_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(train_loader)\n\u001b[0;32m     95\u001b[0m     test_loss, test_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_step(test_loader)\n\u001b[0;32m     97\u001b[0m     loss[\u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\Modules\\PyTorch_Training.py:37\u001b[0m, in \u001b[0;36mModel_Train_Test.train_step\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m     34\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     35\u001b[0m train_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_collection\u001b[39m.\u001b[39mclone(prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):  \u001b[39m# Enables dataloader batching\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     39\u001b[0m     pred_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(X)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\Modules\\PyTorch_Training.py:18\u001b[0m, in \u001b[0;36mSMILES_Features_Dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m---> 18\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39miloc[idx]\n\u001b[0;32m     19\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx]\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor([features], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32), torch\u001b[39m.\u001b[39mtensor([labels], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "from Modules import Fingerprint_Comparator\n",
    "\n",
    "df = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "\n",
    "print(df)\n",
    "\n",
    "Fingerprint_Comparator.Pytorch_Train(df.iloc[:,0], df.iloc[:,1], model0, 2048, metric_collection).regular_fingerprint([\"ecfp\", \"ecfp-count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    train_metrics = metric_collection.clone(prefix=\"train_\")\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        predicted_y = model0(X)\n",
    "        predicted_y = predicted_y.squeeze(1)\n",
    "\n",
    "        loss = loss_fn(predicted_y, y)\n",
    "        train_loss += loss.item()\n",
    "        train_metrics_results = train_metrics(predicted_y, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_metrics_results = train_metrics.compute()\n",
    "    train_metrics.reset()\n",
    "    \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss, train_metrics_results #, predicted_y, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module):\n",
    "    model.eval()\n",
    "    test_metrics = metric_collection.clone(prefix=\"test_\")\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_predicted_y = model0(X)\n",
    "            test_predicted_y = test_predicted_y.squeeze(1)\n",
    "            # print(test_predicted_y.shape); print(y.shape)#  Uncomment to confirm shape\n",
    "\n",
    "            loss = loss_fn(test_predicted_y, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            test_metrics_results = test_metrics(test_predicted_y, y)\n",
    "        \n",
    "        test_metrics_results = test_metrics.compute()\n",
    "        test_metrics.reset()\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    \n",
    "    return test_loss, test_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metics_tensor_dict_to_floats(metrics):\n",
    "    return {key: value.to(device='cpu', non_blocking=True).item() if hasattr(value, 'to') \n",
    "else value for key, value in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module, dataset: torch.utils.data.Dataset, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module = nn.BCELoss(), epochs: int = 10, k_folds: int = 5, batch_size: int = 256, DP:int = 3):\n",
    "    kfold = StratifiedKFold(k_folds, shuffle=True, random_state=42)\n",
    "    score_df = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset, dataset.labels)): \n",
    "        loss = {\"train_loss\": [], \"test_loss\": []}\n",
    "        \n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        test_dataset = torch.utils.data.Subset(dataset, test_idx)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "        \n",
    "        reset_weights(model)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # tracker.increment()\n",
    "            train_loss, train_metrics = train_step(model=model, dataloader=train_loader, loss_fn=loss_fn, optimizer=optimizer)\n",
    "            # tracker.update(predicted_y, y)\n",
    "            test_loss, test_metrics = test_step(model=model, dataloader=test_loader, loss_fn=loss_fn)\n",
    "\n",
    "            train_metrics, test_metrics = metics_tensor_dict_to_floats(train_metrics), metics_tensor_dict_to_floats(test_metrics)\n",
    "            loss[\"train_loss\"].append(train_loss)\n",
    "            loss[\"test_loss\"].append(test_loss)\n",
    "            \n",
    "            if EarlyStopper().early_stop(test_loss):\n",
    "                break\n",
    "\n",
    "        score_df.append(pd.DataFrame.from_dict(test_metrics, orient=\"index\").transpose().round(DP))\n",
    "        \n",
    "        print(f\"Fold {fold+1} final results after {epoch+1} epochs: Train Acc: {train_metrics['train_BinaryAccuracy']:.{DP}f} Train Loss: {train_loss:.{DP}f} (n = {len(train_idx)}) | Test Acc: {test_metrics['test_BinaryAccuracy']:.{DP}f} Test Loss: {test_loss:.{DP}f} (n = {len(test_idx)}) \")\n",
    "\n",
    "    score_df = pd.concat(score_df)\n",
    "    score_df.insert(0, \"Fold\", range(k_folds))\n",
    "    score_df.set_index(\"Fold\", inplace=True)\n",
    "    \n",
    "    return loss, score_df #, tracker.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\pytorch_DILI_CrossVal.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model0\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reset_weights(model0)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model0_loss, model0_df \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39mmodel0, dataset\u001b[39m=\u001b[39mdilidataset, optimizer\u001b[39m=\u001b[39moptimizer, loss_fn\u001b[39m=\u001b[39mloss_fn, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, k_folds\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model0.parameters(), lr=1e-4)\n",
    "\n",
    "reset_weights(model0)\n",
    "model0_loss, model0_df = train(model=model0, dataset=dilidataset, optimizer=optimizer, loss_fn=loss_fn, epochs=1, k_folds=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 1 epochs: Train Acc: 0.000 Train Loss: 0.690 (n = 1875) | Test Acc: 0.000 Test Loss: 0.685 (n = 469) \n",
      "Results after 2 epochs: Train Acc: 0.571 Train Loss: 0.675 (n = 1875) | Test Acc: 0.671 Test Loss: 0.676 (n = 469) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'train_loss': [0.6896825283765793, 0.6748193502426147],\n",
       "  'test_loss': [0.6847695708274841, 0.675948828458786]},\n",
       "        test_BinaryAccuracy  test_BinaryAUROC  test_BinaryMatthewsCorrCoef\n",
       " Epoch                                                                    \n",
       " 0                    0.000             0.000                        0.000\n",
       " 1                    0.671             0.725                        0.616)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Modules import PyTorch_Training\n",
    "\n",
    "PyTorch_Training.Model_Train_Test(model0, metric_collection, loss_fn=loss_fn).train_model(dilidataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 final results after 10 epochs: Train Acc: 0.389 Train Loss: 0.494 (n = 1875) | Test Acc: 0.877 Test Loss: 0.575 (n = 469) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.377 Train Loss: 0.491 (n = 1875) | Test Acc: 0.875 Test Loss: 0.579 (n = 469) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\pytorch_DILI_CrossVal.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m DILIlabels \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m dilidataset \u001b[39m=\u001b[39m DILIDataset(DILIfeatures, DILIlabels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss, score_df \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39mmodel0, dataset\u001b[39m=\u001b[39mdilidataset, optimizer\u001b[39m=\u001b[39moptimizer, loss_fn\u001b[39m=\u001b[39mloss_fn, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, k_folds\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m fp_df\u001b[39m.\u001b[39mappend(score_df)\n",
      "\u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\pytorch_DILI_CrossVal.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m reset_weights(model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# tracker.increment()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     train_loss, train_metrics \u001b[39m=\u001b[39m train_step(model\u001b[39m=\u001b[39mmodel, dataloader\u001b[39m=\u001b[39mtrain_loader, loss_fn\u001b[39m=\u001b[39mloss_fn, optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# tracker.update(predicted_y, y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     test_loss, test_metrics \u001b[39m=\u001b[39m test_step(model\u001b[39m=\u001b[39mmodel, dataloader\u001b[39m=\u001b[39mtest_loader, loss_fn\u001b[39m=\u001b[39mloss_fn)\n",
      "\u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\pytorch_DILI_CrossVal.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_metrics \u001b[39m=\u001b[39m metric_collection\u001b[39m.\u001b[39mclone(prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_loss, train_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     predicted_y \u001b[39m=\u001b[39m model0(X)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\Luke\\anaconda3\\envs\\honours\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(batch, \u001b[39m0\u001b[39m, out\u001b[39m=\u001b[39mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regular_fingerprints = [\n",
    "    \"ecfp\",\n",
    "    \"ecfp-count\",\n",
    "    \"fcfp\"\n",
    "]\n",
    "df = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "\n",
    "fp_df = []\n",
    "\n",
    "\n",
    "\n",
    "for fingerprint in regular_fingerprints:\n",
    "    df = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "    df = Fingerprint_Generator.generate_fp_column(df, df.smiles, fp_type=fingerprint)\n",
    "    df = df.drop(\"smiles\", axis=1)\n",
    "    \n",
    "    DILIfeatures = df.iloc[:, 1]\n",
    "    DILIlabels = df.iloc[:, 0]\n",
    "    \n",
    "    dilidataset = DILIDataset(DILIfeatures, DILIlabels)\n",
    "    \n",
    "    \n",
    "    loss, score_df = train(model=model0, dataset=dilidataset, optimizer=optimizer, loss_fn=loss_fn, epochs=10, k_folds=5, batch_size=256)\n",
    "    \n",
    "    fp_df.append(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=2.8000000000000043, pvalue=0.24659696394160596)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(fp_df)\n",
    "\n",
    "from scipy.stats import wilcoxon, friedmanchisquare\n",
    "\n",
    "# print(fp_df[0].iloc[:, 1]); print(fp_df[1].iloc[:, 1])\n",
    "\n",
    "friedmanchisquare(fp_df[0].iloc[:, 1], fp_df[1].iloc[:, 1], fp_df[2].iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_curve(results: dict[str, list[float]]):\n",
    "    train_loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.plot(train_loss, label=\"train_loss\")\n",
    "    plt.plot(test_loss, label=\"test_loss\")\n",
    "    \n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_loss_curve(model0_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Modules import My_Pytorch_Utilities\n",
    "\n",
    "# dummy_data = torch.rand([1, 2048])\n",
    "\n",
    "# dummy_data.shape\n",
    "\n",
    "# My_Pytorch_Utilities.save(model0, \"DILIst\", dummy_data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fingerprint_Comparator.__init__() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\pytorch_DILI_CrossVal.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m validation_smiles_labels \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m regular_fingerprints \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mecfp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfcfp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msecfp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Luke/Documents/University/5th%20Year/Honours%20Python/pytorch_DILI_CrossVal.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m PyTorch_Pretrained_Inference\u001b[39m.\u001b[39mDILI_Inference(validation_smiles, model0)\u001b[39m.\u001b[39mregular_fingerprint(regular_fingerprints)\n",
      "File \u001b[1;32mc:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\Modules\\PyTorch_Pretrained_Inference.py:25\u001b[0m, in \u001b[0;36mDILI_Inference.__init__\u001b[1;34m(self, smiles, pretrained_model)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, smiles: pd\u001b[39m.\u001b[39mSeries \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m], pretrained_model: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(smiles)\n\u001b[0;32m     26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_model \u001b[39m=\u001b[39m pretrained_model\n\u001b[0;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fingerprint_Comparator.__init__() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "from Modules import PyTorch_Pretrained_Inference\n",
    "\n",
    "validation_smiles = [\"CCC\", \"CCCC\", \"Fc1ccc(cc1)[C@@]3(OCc2cc(C#N)ccc23)CCCN(C)C\"]\n",
    "validation_smiles_labels = [1, 0, 1]\n",
    "\n",
    "regular_fingerprints = [\n",
    "    \"ecfp\",\n",
    "    \"fcfp\",\n",
    "    \"secfp\",\n",
    "]\n",
    "\n",
    "PyTorch_Pretrained_Inference.DILI_Inference(validation_smiles, model0).regular_fingerprint(regular_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 272.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fingerprint type</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecfp</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fcfp</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>secfp</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fingerprint type       acc\n",
       "0             ecfp  0.333333\n",
       "1             fcfp  0.333333\n",
       "2            secfp  0.333333"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Modules import Fingerprint_Comparator\n",
    "\n",
    "Fingerprint_Comparator.PyTorch_Pretrained(validation_smiles, validation_smiles_labels, model0).regular_fingerprint(regular_fingerprints, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Assuming you have loaded_model and device available\n",
    "\n",
    "# from Modules import Fingerprint_Generator\n",
    "\n",
    "# validation_smiles = [\"CCC\", \"CCCC\", \"Fc1ccc(cc1)[C@@]3(OCc2cc(C#N)ccc23)CCCN(C)C\"]\n",
    "\n",
    "# def evaluate_smiles(model, input_smiles):\n",
    "#     scores = {}\n",
    "#     validation_fp = Fingerprint_Generator.Smiles_To_Fingerprint(input_smiles, fingerprint).astype(torch.Tensor).squeeze(1).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         model0.eval()\n",
    "#         for i, input in enumerate(validation_fp):\n",
    "#             output = model(input)\n",
    "#             scores.update({round(output.item(), 3): validation_smiles[i]})\n",
    "#             # scores.append(output.item())\n",
    "#         return scores\n",
    "\n",
    "# print(evaluate_smiles(model0, validation_smiles))\n",
    "\n",
    "\n",
    "# # print(f\"Prediction for {validation_smiles}: {prediction:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honours",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
