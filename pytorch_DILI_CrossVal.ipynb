{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import seaborn as sns\n",
    "from torchmetrics import MetricCollection, classification\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "from Modules import PyTorch_Training, Fingerprint_Generator, Misc_Utils, Fingerprint_Comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              smiles  label\n",
      "0  CN(C)C(=N)N=C(N)N      0\n",
      "1   COC(=O)C=CC(=O)O      0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "df_train = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "df_test = pd.read_csv('Transformed_Data/rega_test.csv')\n",
    "\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "DILI_model = PyTorch_Training.DILI_Models.DILI_Predictor_Sequential(2048, 512, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_collection = MetricCollection([\n",
    "    classification.Accuracy(task='binary', average='macro'),  # Balanced accuracy\n",
    "    classification.BinaryAUROC(),\n",
    "    classification.BinaryMatthewsCorrCoef(),\n",
    "    classification.BinaryPrecision(),\n",
    "    classification.BinaryF1Score(),\n",
    "    classification.BinarySpecificity(),\n",
    "    classification.BinaryJaccardIndex(),\n",
    "    ]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------maccs-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luke\\Documents\\University\\5th Year\\Honours Python\\Modules\\My_Pytorch_Utilities.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return torch.tensor([features], dtype=torch.float32), torch.tensor([labels], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 final results after 10 epochs: Train Acc: 0.509 Train Loss: 0.667 (n = 2109) | Test Acc: 0.558 Test Loss: 0.658 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.437 Train Loss: 0.648 (n = 2109) | Test Acc: 0.586 Test Loss: 0.674 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.557 Train Loss: 0.653 (n = 2109) | Test Acc: 0.597 Test Loss: 0.663 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.456 Train Loss: 0.659 (n = 2109) | Test Acc: 0.599 Test Loss: 0.657 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.478 Train Loss: 0.666 (n = 2110) | Test Acc: 0.468 Test Loss: 0.674 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.636 Train Loss: 0.648 (n = 2110) | Test Acc: 0.542 Test Loss: 0.658 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.635 Train Loss: 0.665 (n = 2110) | Test Acc: 0.578 Test Loss: 0.641 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.506 Train Loss: 0.651 (n = 2110) | Test Acc: 0.621 Test Loss: 0.644 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.524 Train Loss: 0.657 (n = 2110) | Test Acc: 0.571 Test Loss: 0.652 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.494 Train Loss: 0.666 (n = 2110) | Test Acc: 0.528 Test Loss: 0.662 (n = 234) \n",
      "-------------------------------------------------------------ecfp--------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.722 Train Loss: 0.279 (n = 2109) | Test Acc: 0.872 Test Loss: 0.589 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.533 Train Loss: 0.386 (n = 2109) | Test Acc: 0.813 Test Loss: 0.579 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.521 Train Loss: 0.394 (n = 2109) | Test Acc: 0.828 Test Loss: 0.595 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.757 Train Loss: 0.409 (n = 2109) | Test Acc: 0.828 Test Loss: 0.541 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.588 Train Loss: 0.398 (n = 2110) | Test Acc: 0.720 Test Loss: 0.545 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.549 Train Loss: 0.402 (n = 2110) | Test Acc: 0.810 Test Loss: 0.586 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.832 Train Loss: 0.417 (n = 2110) | Test Acc: 0.720 Test Loss: 0.533 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.827 Train Loss: 0.410 (n = 2110) | Test Acc: 0.725 Test Loss: 0.550 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.825 Train Loss: 0.413 (n = 2110) | Test Acc: 0.715 Test Loss: 0.566 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.830 Train Loss: 0.400 (n = 2110) | Test Acc: 0.721 Test Loss: 0.534 (n = 234) \n",
      "----------------------------------------------------------ecfp-count-----------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.869 Train Loss: 0.352 (n = 2109) | Test Acc: 0.779 Test Loss: 0.558 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.849 Train Loss: 0.373 (n = 2109) | Test Acc: 0.753 Test Loss: 0.585 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.542 Train Loss: 0.392 (n = 2109) | Test Acc: 0.590 Test Loss: 0.618 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.533 Train Loss: 0.422 (n = 2109) | Test Acc: 0.797 Test Loss: 0.578 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.687 Train Loss: 0.410 (n = 2110) | Test Acc: 0.715 Test Loss: 0.598 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.823 Train Loss: 0.413 (n = 2110) | Test Acc: 0.711 Test Loss: 0.570 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.823 Train Loss: 0.419 (n = 2110) | Test Acc: 0.715 Test Loss: 0.556 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.829 Train Loss: 0.425 (n = 2110) | Test Acc: 0.709 Test Loss: 0.554 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.828 Train Loss: 0.414 (n = 2110) | Test Acc: 0.725 Test Loss: 0.572 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.815 Train Loss: 0.424 (n = 2110) | Test Acc: 0.702 Test Loss: 0.535 (n = 234) \n",
      "------------------------------------------------------------avalon-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.561 Train Loss: 0.613 (n = 2109) | Test Acc: 0.513 Test Loss: 0.607 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.456 Train Loss: 0.592 (n = 2109) | Test Acc: 0.677 Test Loss: 0.654 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.666 Train Loss: 0.608 (n = 2109) | Test Acc: 0.628 Test Loss: 0.645 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.651 Train Loss: 0.617 (n = 2109) | Test Acc: 0.651 Test Loss: 0.617 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.419 Train Loss: 0.608 (n = 2110) | Test Acc: 0.510 Test Loss: 0.633 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.548 Train Loss: 0.608 (n = 2110) | Test Acc: 0.598 Test Loss: 0.637 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.651 Train Loss: 0.612 (n = 2110) | Test Acc: 0.573 Test Loss: 0.607 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.661 Train Loss: 0.617 (n = 2110) | Test Acc: 0.526 Test Loss: 0.622 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.659 Train Loss: 0.612 (n = 2110) | Test Acc: 0.615 Test Loss: 0.627 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.515 Train Loss: 0.612 (n = 2110) | Test Acc: 0.506 Test Loss: 0.601 (n = 234) \n",
      "-------------------------------------------------------------fcfp--------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.856 Train Loss: 0.350 (n = 2109) | Test Acc: 0.837 Test Loss: 0.589 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.791 Train Loss: 0.442 (n = 2109) | Test Acc: 0.705 Test Loss: 0.561 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.536 Train Loss: 0.426 (n = 2109) | Test Acc: 0.672 Test Loss: 0.623 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.722 Train Loss: 0.425 (n = 2109) | Test Acc: 0.706 Test Loss: 0.537 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.808 Train Loss: 0.445 (n = 2110) | Test Acc: 0.697 Test Loss: 0.521 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.594 Train Loss: 0.447 (n = 2110) | Test Acc: 0.688 Test Loss: 0.563 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.572 Train Loss: 0.461 (n = 2110) | Test Acc: 0.672 Test Loss: 0.526 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.545 Train Loss: 0.448 (n = 2110) | Test Acc: 0.675 Test Loss: 0.575 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.810 Train Loss: 0.439 (n = 2110) | Test Acc: 0.722 Test Loss: 0.589 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.805 Train Loss: 0.452 (n = 2110) | Test Acc: 0.686 Test Loss: 0.516 (n = 234) \n",
      "-------------------------------------------------------------secfp-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.626 Train Loss: 0.257 (n = 2109) | Test Acc: 0.917 Test Loss: 0.668 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.853 Train Loss: 0.366 (n = 2109) | Test Acc: 0.755 Test Loss: 0.595 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.851 Train Loss: 0.380 (n = 2109) | Test Acc: 0.747 Test Loss: 0.573 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.853 Train Loss: 0.370 (n = 2109) | Test Acc: 0.677 Test Loss: 0.580 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.853 Train Loss: 0.380 (n = 2110) | Test Acc: 0.748 Test Loss: 0.533 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.552 Train Loss: 0.373 (n = 2110) | Test Acc: 0.698 Test Loss: 0.593 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.857 Train Loss: 0.384 (n = 2110) | Test Acc: 0.718 Test Loss: 0.531 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.858 Train Loss: 0.377 (n = 2110) | Test Acc: 0.697 Test Loss: 0.563 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.845 Train Loss: 0.387 (n = 2110) | Test Acc: 0.726 Test Loss: 0.585 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.847 Train Loss: 0.379 (n = 2110) | Test Acc: 0.746 Test Loss: 0.559 (n = 234) \n",
      "----------------------------------------------------------topological----------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.565 Train Loss: 0.395 (n = 2109) | Test Acc: 0.697 Test Loss: 0.608 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.541 Train Loss: 0.464 (n = 2109) | Test Acc: 0.735 Test Loss: 0.589 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.780 Train Loss: 0.475 (n = 2109) | Test Acc: 0.659 Test Loss: 0.579 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.785 Train Loss: 0.470 (n = 2109) | Test Acc: 0.666 Test Loss: 0.566 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.779 Train Loss: 0.475 (n = 2110) | Test Acc: 0.660 Test Loss: 0.585 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.788 Train Loss: 0.468 (n = 2110) | Test Acc: 0.664 Test Loss: 0.581 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.791 Train Loss: 0.459 (n = 2110) | Test Acc: 0.762 Test Loss: 0.566 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.585 Train Loss: 0.484 (n = 2110) | Test Acc: 0.744 Test Loss: 0.557 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.525 Train Loss: 0.473 (n = 2110) | Test Acc: 0.746 Test Loss: 0.630 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.601 Train Loss: 0.465 (n = 2110) | Test Acc: 0.711 Test Loss: 0.560 (n = 234) \n",
      "-----------------------------------------------------------atompair------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.855 Train Loss: 0.360 (n = 2109) | Test Acc: 0.706 Test Loss: 0.603 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.503 Train Loss: 0.407 (n = 2109) | Test Acc: 0.790 Test Loss: 0.606 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.812 Train Loss: 0.432 (n = 2109) | Test Acc: 0.660 Test Loss: 0.601 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.805 Train Loss: 0.439 (n = 2109) | Test Acc: 0.689 Test Loss: 0.586 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.800 Train Loss: 0.457 (n = 2110) | Test Acc: 0.688 Test Loss: 0.590 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.809 Train Loss: 0.443 (n = 2110) | Test Acc: 0.688 Test Loss: 0.592 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.787 Train Loss: 0.461 (n = 2110) | Test Acc: 0.705 Test Loss: 0.571 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.794 Train Loss: 0.456 (n = 2110) | Test Acc: 0.701 Test Loss: 0.577 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.790 Train Loss: 0.454 (n = 2110) | Test Acc: 0.684 Test Loss: 0.613 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.784 Train Loss: 0.466 (n = 2110) | Test Acc: 0.739 Test Loss: 0.531 (n = 234) \n",
      "-------------------------------------------------------------rdkit-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.601 Train Loss: 0.368 (n = 2109) | Test Acc: 0.836 Test Loss: 0.613 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.542 Train Loss: 0.414 (n = 2109) | Test Acc: 0.814 Test Loss: 0.570 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.473 Train Loss: 0.431 (n = 2109) | Test Acc: 0.674 Test Loss: 0.688 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.439 Train Loss: 0.451 (n = 2109) | Test Acc: 0.794 Test Loss: 0.539 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.722 Train Loss: 0.458 (n = 2110) | Test Acc: 0.773 Test Loss: 0.584 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.588 Train Loss: 0.470 (n = 2110) | Test Acc: 0.768 Test Loss: 0.581 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.558 Train Loss: 0.457 (n = 2110) | Test Acc: 0.803 Test Loss: 0.579 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.658 Train Loss: 0.452 (n = 2110) | Test Acc: 0.794 Test Loss: 0.566 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.580 Train Loss: 0.448 (n = 2110) | Test Acc: 0.800 Test Loss: 0.619 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.583 Train Loss: 0.459 (n = 2110) | Test Acc: 0.778 Test Loss: 0.553 (n = 234) \n",
      "------------------------------------------------------------pattern------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.451 Train Loss: 0.472 (n = 2109) | Test Acc: 0.789 Test Loss: 0.577 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.739 Train Loss: 0.507 (n = 2109) | Test Acc: 0.723 Test Loss: 0.635 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.570 Train Loss: 0.502 (n = 2109) | Test Acc: 0.738 Test Loss: 0.652 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.483 Train Loss: 0.521 (n = 2109) | Test Acc: 0.603 Test Loss: 0.576 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.575 Train Loss: 0.523 (n = 2110) | Test Acc: 0.694 Test Loss: 0.594 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.723 Train Loss: 0.532 (n = 2110) | Test Acc: 0.567 Test Loss: 0.611 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.733 Train Loss: 0.535 (n = 2110) | Test Acc: 0.591 Test Loss: 0.574 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.725 Train Loss: 0.532 (n = 2110) | Test Acc: 0.662 Test Loss: 0.604 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.732 Train Loss: 0.528 (n = 2110) | Test Acc: 0.590 Test Loss: 0.631 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.732 Train Loss: 0.526 (n = 2110) | Test Acc: 0.722 Test Loss: 0.553 (n = 234) \n",
      "------------------------------------------------------------layered------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.811 Train Loss: 0.423 (n = 2109) | Test Acc: 0.687 Test Loss: 0.588 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.448 Train Loss: 0.446 (n = 2109) | Test Acc: 0.655 Test Loss: 0.588 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.426 Train Loss: 0.466 (n = 2109) | Test Acc: 0.797 Test Loss: 0.614 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.536 Train Loss: 0.468 (n = 2109) | Test Acc: 0.778 Test Loss: 0.527 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.583 Train Loss: 0.473 (n = 2110) | Test Acc: 0.740 Test Loss: 0.554 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.548 Train Loss: 0.474 (n = 2110) | Test Acc: 0.767 Test Loss: 0.585 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.439 Train Loss: 0.489 (n = 2110) | Test Acc: 0.734 Test Loss: 0.615 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.580 Train Loss: 0.487 (n = 2110) | Test Acc: 0.757 Test Loss: 0.559 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.532 Train Loss: 0.458 (n = 2110) | Test Acc: 0.792 Test Loss: 0.581 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.447 Train Loss: 0.497 (n = 2110) | Test Acc: 0.732 Test Loss: 0.570 (n = 234) \n"
     ]
    }
   ],
   "source": [
    "regular_fingerprints = Fingerprint_Generator.Fingerprint_Lists().regular_fingerprints(abridged_set=True, abridged_count=2)\n",
    "\n",
    "comparator = Fingerprint_Comparator.Pytorch_Train(df_train.iloc[:,0], df_train.iloc[:,1], DILI_model, 2048, metric_collection)\n",
    "\n",
    "comparator_results, comparator_results_multiindex = comparator.regular_fingerprint(regular_fingerprints, k_folds=10, epochs=10)\n",
    "\n",
    "comparator_results.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Fingerprint</th>\n",
       "      <th>Fold</th>\n",
       "      <th>test_BinaryAccuracy</th>\n",
       "      <th>test_BinaryAUROC</th>\n",
       "      <th>test_BinaryMatthewsCorrCoef</th>\n",
       "      <th>test_BinaryPrecision</th>\n",
       "      <th>test_BinaryF1Score</th>\n",
       "      <th>test_BinarySpecificity</th>\n",
       "      <th>test_BinaryJaccardIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>maccs</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Fingerprint  Fold  test_BinaryAccuracy  test_BinaryAUROC  \\\n",
       "0      0       maccs     0                0.558             0.473   \n",
       "\n",
       "   test_BinaryMatthewsCorrCoef  test_BinaryPrecision  test_BinaryF1Score  \\\n",
       "0                        0.647                 0.732               0.294   \n",
       "\n",
       "   test_BinarySpecificity  test_BinaryJaccardIndex  \n",
       "0                   0.637                    0.675  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparator_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_comparator_output, mean_score = Misc_Utils.get_average_score(comparator_results, \"test_BinaryAccuracy\", \"Fingerprint\", normalize_scores=True)\n",
    "\n",
    "# comparator_results_means = comparator_results.iloc[:,2] - mean_score\n",
    "# comparator_results_means = comparator_results_means.sort_values(ascending=False)\n",
    "fp_plot = sns.barplot(\n",
    "    data = mean_comparator_output,\n",
    "    x='Fingerprint',\n",
    "    y='test_BinaryAccuracy',\n",
    "    hue=\"Fingerprint\",\n",
    "    errorbar=None,\n",
    "    bottom=mean_score,\n",
    ")\n",
    "\n",
    "\n",
    "# The semicolons at the line end stop Seaborn printing a dataframe\n",
    "fp_plot.xaxis.set_ticks(comparator_results[\"Fingerprint\"])\n",
    "# Prevent Seaborn error if x-axis ticks not explicitly defined before the next line is run\n",
    "fp_plot.set_xticklabels(fp_plot.get_xticklabels(), rotation=40, ha=\"right\");  # Rotate X-axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_scores = []\n",
    "\n",
    "for fingerprint in regular_fingerprints:\n",
    "    fp_and_acc = comparator_results.filter([\"Fingerprint\", \"test_BinaryAccuracy\"], axis=1)\n",
    "    fp_and_acc = (fp_and_acc.query('Fingerprint == @fingerprint'))\n",
    "    list_of_scores.append(fp_and_acc)\n",
    "\n",
    "\n",
    "friedman_stat, friedman_p = friedmanchisquare(*[list_of_scores[x].iloc[:, 1] for x in range(len(list_of_scores))])\n",
    "print(friedman_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_curve(results: dict[str, list[float]]):\n",
    "    train_loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.plot(train_loss, label=\"train_loss\")\n",
    "    plt.plot(test_loss, label=\"test_loss\")\n",
    "    \n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_loss_curve(model0_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Modules import My_Pytorch_Utilities\n",
    "\n",
    "# dummy_data = torch.rand([1, 2048])\n",
    "\n",
    "# dummy_data.shape\n",
    "\n",
    "# My_Pytorch_Utilities.save(model0, \"DILIst\", dummy_data.to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honours",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
