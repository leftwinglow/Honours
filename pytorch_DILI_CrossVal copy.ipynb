{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import seaborn as sns\n",
    "from torchmetrics import MetricCollection, classification\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "\n",
    "from Modules import PyTorch_Training, Fingerprint_Generator, My_Pytorch_Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              smiles  label\n",
      "0  CN(C)C(=N)N=C(N)N      0\n",
      "1   COC(=O)C=CC(=O)O      0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "df_train = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "df_test = pd.read_csv('Transformed_Data/rega_test.csv')\n",
    "\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "DILI_model = PyTorch_Training.DILI_Models.DILI_Predictor_Sequential(2048, 512, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_collection = MetricCollection([\n",
    "    classification.Accuracy(task='binary', average='macro').to(device),  # Balanced accuracy\n",
    "    classification.BinaryAUROC().to(device),\n",
    "    classification.BinaryMatthewsCorrCoef().to(device)\n",
    "    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------maccs-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.388 Train Loss: 0.605 (n = 2109) | Test Acc: 0.729 Test Loss: 0.601 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.148 Train Loss: 0.592 (n = 2109) | Test Acc: 0.741 Test Loss: 0.669 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.319 Train Loss: 0.615 (n = 2109) | Test Acc: 0.726 Test Loss: 0.648 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.721 Train Loss: 0.612 (n = 2109) | Test Acc: 0.685 Test Loss: 0.607 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.224 Train Loss: 0.611 (n = 2110) | Test Acc: 0.329 Test Loss: 0.632 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.214 Train Loss: 0.611 (n = 2110) | Test Acc: 0.723 Test Loss: 0.648 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.345 Train Loss: 0.615 (n = 2110) | Test Acc: 0.719 Test Loss: 0.589 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.273 Train Loss: 0.617 (n = 2110) | Test Acc: 0.717 Test Loss: 0.614 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.350 Train Loss: 0.617 (n = 2110) | Test Acc: 0.717 Test Loss: 0.616 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.290 Train Loss: 0.621 (n = 2110) | Test Acc: 0.684 Test Loss: 0.610 (n = 234) \n",
      "------------------------------------------------------------avalon-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.449 Train Loss: 0.549 (n = 2109) | Test Acc: 0.777 Test Loss: 0.579 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.661 Train Loss: 0.572 (n = 2109) | Test Acc: 0.779 Test Loss: 0.660 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.677 Train Loss: 0.578 (n = 2109) | Test Acc: 0.609 Test Loss: 0.628 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.732 Train Loss: 0.589 (n = 2109) | Test Acc: 0.756 Test Loss: 0.593 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.263 Train Loss: 0.591 (n = 2110) | Test Acc: 0.637 Test Loss: 0.637 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.265 Train Loss: 0.584 (n = 2110) | Test Acc: 0.758 Test Loss: 0.631 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.334 Train Loss: 0.579 (n = 2110) | Test Acc: 0.763 Test Loss: 0.611 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.316 Train Loss: 0.588 (n = 2110) | Test Acc: 0.762 Test Loss: 0.612 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.715 Train Loss: 0.591 (n = 2110) | Test Acc: 0.752 Test Loss: 0.612 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.375 Train Loss: 0.587 (n = 2110) | Test Acc: 0.375 Test Loss: 0.579 (n = 234) \n",
      "-------------------------------------------------------------ecfp--------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.794 Train Loss: 0.437 (n = 2109) | Test Acc: 0.672 Test Loss: 0.549 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.775 Train Loss: 0.477 (n = 2109) | Test Acc: 0.595 Test Loss: 0.590 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.356 Train Loss: 0.501 (n = 2109) | Test Acc: 0.572 Test Loss: 0.600 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.404 Train Loss: 0.522 (n = 2109) | Test Acc: 0.853 Test Loss: 0.559 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.786 Train Loss: 0.523 (n = 2110) | Test Acc: 0.548 Test Loss: 0.563 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.743 Train Loss: 0.510 (n = 2110) | Test Acc: 0.557 Test Loss: 0.585 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.393 Train Loss: 0.515 (n = 2110) | Test Acc: 0.556 Test Loss: 0.554 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.436 Train Loss: 0.513 (n = 2110) | Test Acc: 0.851 Test Loss: 0.576 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.763 Train Loss: 0.506 (n = 2110) | Test Acc: 0.559 Test Loss: 0.579 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.485 Train Loss: 0.498 (n = 2110) | Test Acc: 0.860 Test Loss: 0.549 (n = 234) \n",
      "-------------------------------------------------------------fcfp--------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.781 Train Loss: 0.472 (n = 2109) | Test Acc: 0.875 Test Loss: 0.568 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.740 Train Loss: 0.515 (n = 2109) | Test Acc: 0.841 Test Loss: 0.593 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.367 Train Loss: 0.527 (n = 2109) | Test Acc: 0.840 Test Loss: 0.618 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.390 Train Loss: 0.545 (n = 2109) | Test Acc: 0.689 Test Loss: 0.574 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.783 Train Loss: 0.533 (n = 2110) | Test Acc: 0.827 Test Loss: 0.556 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.757 Train Loss: 0.518 (n = 2110) | Test Acc: 0.839 Test Loss: 0.573 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.788 Train Loss: 0.537 (n = 2110) | Test Acc: 0.718 Test Loss: 0.548 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.717 Train Loss: 0.545 (n = 2110) | Test Acc: 0.822 Test Loss: 0.603 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.739 Train Loss: 0.549 (n = 2110) | Test Acc: 0.705 Test Loss: 0.603 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.781 Train Loss: 0.544 (n = 2110) | Test Acc: 0.822 Test Loss: 0.555 (n = 234) \n",
      "----------------------------------------------------------topological----------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.421 Train Loss: 0.503 (n = 2109) | Test Acc: 0.711 Test Loss: 0.581 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.270 Train Loss: 0.523 (n = 2109) | Test Acc: 0.829 Test Loss: 0.603 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.278 Train Loss: 0.540 (n = 2109) | Test Acc: 0.820 Test Loss: 0.591 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.757 Train Loss: 0.551 (n = 2109) | Test Acc: 0.811 Test Loss: 0.579 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.265 Train Loss: 0.542 (n = 2110) | Test Acc: 0.809 Test Loss: 0.598 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.365 Train Loss: 0.544 (n = 2110) | Test Acc: 0.671 Test Loss: 0.595 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.324 Train Loss: 0.555 (n = 2110) | Test Acc: 0.806 Test Loss: 0.576 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.351 Train Loss: 0.535 (n = 2110) | Test Acc: 0.818 Test Loss: 0.579 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.243 Train Loss: 0.545 (n = 2110) | Test Acc: 0.815 Test Loss: 0.622 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.756 Train Loss: 0.542 (n = 2110) | Test Acc: 0.817 Test Loss: 0.571 (n = 234) \n",
      "-----------------------------------------------------------atompair------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.421 Train Loss: 0.477 (n = 2109) | Test Acc: 0.867 Test Loss: 0.577 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.239 Train Loss: 0.504 (n = 2109) | Test Acc: 0.847 Test Loss: 0.622 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.310 Train Loss: 0.515 (n = 2109) | Test Acc: 0.838 Test Loss: 0.595 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.362 Train Loss: 0.503 (n = 2109) | Test Acc: 0.845 Test Loss: 0.579 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.747 Train Loss: 0.497 (n = 2110) | Test Acc: 0.523 Test Loss: 0.599 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.737 Train Loss: 0.519 (n = 2110) | Test Acc: 0.836 Test Loss: 0.586 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.765 Train Loss: 0.522 (n = 2110) | Test Acc: 0.834 Test Loss: 0.573 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.418 Train Loss: 0.506 (n = 2110) | Test Acc: 0.842 Test Loss: 0.569 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.343 Train Loss: 0.498 (n = 2110) | Test Acc: 0.844 Test Loss: 0.641 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.500 Train Loss: 0.516 (n = 2110) | Test Acc: 0.830 Test Loss: 0.532 (n = 234) \n",
      "-------------------------------------------------------------rdkit-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.444 Train Loss: 0.458 (n = 2109) | Test Acc: 0.877 Test Loss: 0.567 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.744 Train Loss: 0.471 (n = 2109) | Test Acc: 0.685 Test Loss: 0.585 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.724 Train Loss: 0.494 (n = 2109) | Test Acc: 0.541 Test Loss: 0.613 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.789 Train Loss: 0.491 (n = 2109) | Test Acc: 0.859 Test Loss: 0.540 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.368 Train Loss: 0.492 (n = 2110) | Test Acc: 0.692 Test Loss: 0.575 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.759 Train Loss: 0.502 (n = 2110) | Test Acc: 0.701 Test Loss: 0.594 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.780 Train Loss: 0.493 (n = 2110) | Test Acc: 0.654 Test Loss: 0.614 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.760 Train Loss: 0.499 (n = 2110) | Test Acc: 0.520 Test Loss: 0.586 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.756 Train Loss: 0.502 (n = 2110) | Test Acc: 0.513 Test Loss: 0.598 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.758 Train Loss: 0.512 (n = 2110) | Test Acc: 0.516 Test Loss: 0.567 (n = 234) \n",
      "------------------------------------------------------------pattern------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.715 Train Loss: 0.549 (n = 2109) | Test Acc: 0.434 Test Loss: 0.604 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.719 Train Loss: 0.551 (n = 2109) | Test Acc: 0.437 Test Loss: 0.636 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.724 Train Loss: 0.547 (n = 2109) | Test Acc: 0.447 Test Loss: 0.647 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.708 Train Loss: 0.563 (n = 2109) | Test Acc: 0.416 Test Loss: 0.576 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.702 Train Loss: 0.555 (n = 2110) | Test Acc: 0.404 Test Loss: 0.598 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.722 Train Loss: 0.549 (n = 2110) | Test Acc: 0.443 Test Loss: 0.629 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.706 Train Loss: 0.562 (n = 2110) | Test Acc: 0.412 Test Loss: 0.554 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.696 Train Loss: 0.560 (n = 2110) | Test Acc: 0.391 Test Loss: 0.613 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.712 Train Loss: 0.564 (n = 2110) | Test Acc: 0.641 Test Loss: 0.621 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.694 Train Loss: 0.568 (n = 2110) | Test Acc: 0.387 Test Loss: 0.568 (n = 234) \n",
      "------------------------------------------------------------layered------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.782 Train Loss: 0.474 (n = 2109) | Test Acc: 0.564 Test Loss: 0.594 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.743 Train Loss: 0.516 (n = 2109) | Test Acc: 0.487 Test Loss: 0.596 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.753 Train Loss: 0.508 (n = 2109) | Test Acc: 0.655 Test Loss: 0.620 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.746 Train Loss: 0.512 (n = 2109) | Test Acc: 0.492 Test Loss: 0.541 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.747 Train Loss: 0.517 (n = 2110) | Test Acc: 0.494 Test Loss: 0.587 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.741 Train Loss: 0.527 (n = 2110) | Test Acc: 0.482 Test Loss: 0.600 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.736 Train Loss: 0.514 (n = 2110) | Test Acc: 0.472 Test Loss: 0.588 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.718 Train Loss: 0.545 (n = 2110) | Test Acc: 0.435 Test Loss: 0.574 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.743 Train Loss: 0.515 (n = 2110) | Test Acc: 0.485 Test Loss: 0.579 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.729 Train Loss: 0.523 (n = 2110) | Test Acc: 0.460 Test Loss: 0.566 (n = 234) \n",
      "-------------------------------------------------------------secfp-------------------------------------------------------------\n",
      "Fold 1 final results after 10 epochs: Train Acc: 0.850 Train Loss: 0.397 (n = 2109) | Test Acc: 0.706 Test Loss: 0.586 (n = 235) \n",
      "Fold 2 final results after 10 epochs: Train Acc: 0.795 Train Loss: 0.485 (n = 2109) | Test Acc: 0.593 Test Loss: 0.585 (n = 235) \n",
      "Fold 3 final results after 10 epochs: Train Acc: 0.788 Train Loss: 0.481 (n = 2109) | Test Acc: 0.575 Test Loss: 0.592 (n = 235) \n",
      "Fold 4 final results after 10 epochs: Train Acc: 0.783 Train Loss: 0.504 (n = 2109) | Test Acc: 0.567 Test Loss: 0.566 (n = 235) \n",
      "Fold 5 final results after 10 epochs: Train Acc: 0.782 Train Loss: 0.491 (n = 2110) | Test Acc: 0.566 Test Loss: 0.554 (n = 234) \n",
      "Fold 6 final results after 10 epochs: Train Acc: 0.398 Train Loss: 0.493 (n = 2110) | Test Acc: 0.697 Test Loss: 0.581 (n = 234) \n",
      "Fold 7 final results after 10 epochs: Train Acc: 0.785 Train Loss: 0.489 (n = 2110) | Test Acc: 0.571 Test Loss: 0.541 (n = 234) \n",
      "Fold 8 final results after 10 epochs: Train Acc: 0.785 Train Loss: 0.498 (n = 2110) | Test Acc: 0.574 Test Loss: 0.571 (n = 234) \n",
      "Fold 9 final results after 10 epochs: Train Acc: 0.786 Train Loss: 0.489 (n = 2110) | Test Acc: 0.576 Test Loss: 0.583 (n = 234) \n",
      "Fold 10 final results after 10 epochs: Train Acc: 0.784 Train Loss: 0.488 (n = 2110) | Test Acc: 0.570 Test Loss: 0.551 (n = 234) \n"
     ]
    }
   ],
   "source": [
    "from Modules import Fingerprint_Comparator\n",
    "\n",
    "# regular_fingerprints = [\n",
    "#     \"maccs\",\n",
    "#     \"avalon\",\n",
    "#     \"ecfp\",\n",
    "# ]\n",
    "\n",
    "regular_fingerprints = [\n",
    "    \"maccs\",\n",
    "    \"avalon\",\n",
    "    \"ecfp\",\n",
    "    \"fcfp\",\n",
    "    \"topological\",\n",
    "    \"atompair\",\n",
    "    \"rdkit\",\n",
    "    \"pattern\",\n",
    "    \"layered\",\n",
    "    \"secfp\",\n",
    "]\n",
    "\n",
    "df_train = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "\n",
    "comparator = Fingerprint_Comparator.Pytorch_Train(df_train.iloc[:,0], df_train.iloc[:,1], DILI_model, 2048, metric_collection)\n",
    "\n",
    "# comparator_results = comparator.regular_fingerprint(regular_fingerprints, pad=True, k_folds=10, epochs=10)\n",
    "\n",
    "comparator_results, comparator_results_multiindex = comparator.regular_fingerprint(regular_fingerprints, pad=True, k_folds=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fingerprint  Fold  test_BinaryAccuracy  test_BinaryAUROC  \\\n",
      "0        maccs     0                0.729             0.319   \n",
      "0        maccs     1                0.741             0.363   \n",
      "0        maccs     2                0.726             0.329   \n",
      "0        maccs     3                0.685             0.685   \n",
      "0        maccs     4                0.329             0.726   \n",
      "..         ...   ...                  ...               ...   \n",
      "0        secfp     5                0.697             0.752   \n",
      "0        secfp     6                0.571             0.735   \n",
      "0        secfp     7                0.574             0.705   \n",
      "0        secfp     8                0.576             0.709   \n",
      "0        secfp     9                0.570             0.744   \n",
      "\n",
      "    test_BinaryMatthewsCorrCoef  \n",
      "0                         0.702  \n",
      "0                         0.570  \n",
      "0                         0.664  \n",
      "0                         0.317  \n",
      "0                         0.632  \n",
      "..                          ...  \n",
      "0                         0.394  \n",
      "0                         0.802  \n",
      "0                         0.768  \n",
      "0                         0.775  \n",
      "0                         0.789  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(comparator_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Fingerprint', ylabel='test_BinaryAccuracy'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_score = comparator_results.iloc[:,2].mean()  # Mean of entire column\n",
    "\n",
    "comparator_results_means = comparator_results.iloc[:,2] - mean_score\n",
    "comparator_results_means = comparator_results_means.sort_values(ascending=False)\n",
    "\n",
    "sns.barplot(\n",
    "    data = comparator_results,\n",
    "    x='Fingerprint',\n",
    "    y='test_BinaryAccuracy',\n",
    "    hue=\"Fingerprint\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.058487269161868e-08\n"
     ]
    }
   ],
   "source": [
    "list_of_scores = []\n",
    "\n",
    "for fingerprint in regular_fingerprints:\n",
    "    fp_and_acc = comparator_results.filter([\"Fingerprint\", \"test_BinaryAccuracy\"], axis=1)\n",
    "    fp_and_acc = (fp_and_acc.query('Fingerprint == @fingerprint'))\n",
    "    list_of_scores.append(fp_and_acc)\n",
    "\n",
    "\n",
    "friedman_stat, friedman_p = friedmanchisquare(*[list_of_scores[x].iloc[:, 1] for x in range(len(list_of_scores))])\n",
    "print(friedman_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    train_metrics = metric_collection.clone(prefix=\"train_\")\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        predicted_y = model0(X)\n",
    "        predicted_y = predicted_y.squeeze(1)\n",
    "\n",
    "        loss = loss_fn(predicted_y, y)\n",
    "        train_loss += loss.item()\n",
    "        train_metrics_results = train_metrics(predicted_y, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_metrics_results = train_metrics.compute()\n",
    "    train_metrics.reset()\n",
    "    \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss, train_metrics_results #, predicted_y, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module):\n",
    "    model.eval()\n",
    "    test_metrics = metric_collection.clone(prefix=\"test_\")\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_predicted_y = model0(X)\n",
    "            test_predicted_y = test_predicted_y.squeeze(1)\n",
    "            # print(test_predicted_y.shape); print(y.shape)#  Uncomment to confirm shape\n",
    "\n",
    "            loss = loss_fn(test_predicted_y, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            test_metrics_results = test_metrics(test_predicted_y, y)\n",
    "        \n",
    "        test_metrics_results = test_metrics.compute()\n",
    "        test_metrics.reset()\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    \n",
    "    return test_loss, test_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metics_tensor_dict_to_floats(metrics):\n",
    "    return {key: value.to(device='cpu', non_blocking=True).item() if hasattr(value, 'to') \n",
    "else value for key, value in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module, dataset: torch.utils.data.Dataset, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module = nn.BCELoss(), epochs: int = 10, k_folds: int = 5, batch_size: int = 256, DP:int = 3):\n",
    "    kfold = StratifiedKFold(k_folds, shuffle=True, random_state=42)\n",
    "    score_df = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset, dataset.labels)): \n",
    "        loss = {\"train_loss\": [], \"test_loss\": []}\n",
    "        \n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        test_dataset = torch.utils.data.Subset(dataset, test_idx)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "        \n",
    "        reset_weights(model)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # tracker.increment()\n",
    "            train_loss, train_metrics = train_step(model=model, dataloader=train_loader, loss_fn=loss_fn, optimizer=optimizer)\n",
    "            # tracker.update(predicted_y, y)\n",
    "            test_loss, test_metrics = test_step(model=model, dataloader=test_loader, loss_fn=loss_fn)\n",
    "\n",
    "            train_metrics, test_metrics = metics_tensor_dict_to_floats(train_metrics), metics_tensor_dict_to_floats(test_metrics)\n",
    "            loss[\"train_loss\"].append(train_loss)\n",
    "            loss[\"test_loss\"].append(test_loss)\n",
    "            \n",
    "            if EarlyStopper().early_stop(test_loss):\n",
    "                break\n",
    "\n",
    "        score_df.append(pd.DataFrame.from_dict(test_metrics, orient=\"index\").transpose().round(DP))\n",
    "        \n",
    "        print(f\"Fold {fold+1} final results after {epoch+1} epochs: Train Acc: {train_metrics['train_BinaryAccuracy']:.{DP}f} Train Loss: {train_loss:.{DP}f} (n = {len(train_idx)}) | Test Acc: {test_metrics['test_BinaryAccuracy']:.{DP}f} Test Loss: {test_loss:.{DP}f} (n = {len(test_idx)}) \")\n",
    "\n",
    "    score_df = pd.concat(score_df)\n",
    "    score_df.insert(0, \"Fold\", range(k_folds))\n",
    "    score_df.set_index(\"Fold\", inplace=True)\n",
    "    \n",
    "    return loss, score_df #, tracker.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model0.parameters(), lr=1e-4)\n",
    "\n",
    "reset_weights(model0)\n",
    "model0_loss, model0_df = train(model=model0, dataset=dilidataset, optimizer=optimizer, loss_fn=loss_fn, epochs=1, k_folds=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules import PyTorch_Training\n",
    "\n",
    "PyTorch_Training.Model_Train_Test(model0, metric_collection, loss_fn=loss_fn).train_model(dilidataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_fingerprints = [\n",
    "    \"ecfp\",\n",
    "    \"ecfp-count\",\n",
    "    \"fcfp\"\n",
    "]\n",
    "df_train = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "\n",
    "fp_df = []\n",
    "\n",
    "\n",
    "\n",
    "for fingerprint in regular_fingerprints:\n",
    "    df_train = pd.read_csv('Transformed_Data/rega_train.csv')\n",
    "    df_train = Fingerprint_Generator.generate_fp_column(df_train, df_train.smiles, fp_type=fingerprint)\n",
    "    df_train = df_train.drop(\"smiles\", axis=1)\n",
    "    \n",
    "    DILIfeatures = df_train.iloc[:, 1]\n",
    "    DILIlabels = df_train.iloc[:, 0]\n",
    "    \n",
    "    dilidataset = DILIDataset(DILIfeatures, DILIlabels)\n",
    "    \n",
    "    \n",
    "    loss, score_df = train(model=model0, dataset=dilidataset, optimizer=optimizer, loss_fn=loss_fn, epochs=10, k_folds=5, batch_size=256)\n",
    "    \n",
    "    fp_df.append(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_curve(results: dict[str, list[float]]):\n",
    "    train_loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.plot(train_loss, label=\"train_loss\")\n",
    "    plt.plot(test_loss, label=\"test_loss\")\n",
    "    \n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_loss_curve(model0_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Modules import My_Pytorch_Utilities\n",
    "\n",
    "# dummy_data = torch.rand([1, 2048])\n",
    "\n",
    "# dummy_data.shape\n",
    "\n",
    "# My_Pytorch_Utilities.save(model0, \"DILIst\", dummy_data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules import PyTorch_Pretrained_Inference\n",
    "\n",
    "validation_smiles = [\"CCC\", \"CCCC\", \"Fc1ccc(cc1)[C@@]3(OCc2cc(C#N)ccc23)CCCN(C)C\"]\n",
    "validation_smiles_labels = [1, 0, 1]\n",
    "\n",
    "regular_fingerprints = [\n",
    "    \"ecfp\",\n",
    "    \"fcfp\",\n",
    "    \"secfp\",\n",
    "]\n",
    "\n",
    "PyTorch_Pretrained_Inference.DILI_Inference(validation_smiles, model0).regular_fingerprint(regular_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules import Fingerprint_Comparator\n",
    "\n",
    "Fingerprint_Comparator.PyTorch_Pretrained(validation_smiles, validation_smiles_labels, model0).regular_fingerprint(regular_fingerprints, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Assuming you have loaded_model and device available\n",
    "\n",
    "# from Modules import Fingerprint_Generator\n",
    "\n",
    "# validation_smiles = [\"CCC\", \"CCCC\", \"Fc1ccc(cc1)[C@@]3(OCc2cc(C#N)ccc23)CCCN(C)C\"]\n",
    "\n",
    "# def evaluate_smiles(model, input_smiles):\n",
    "#     scores = {}\n",
    "#     validation_fp = Fingerprint_Generator.Smiles_To_Fingerprint(input_smiles, fingerprint).astype(torch.Tensor).squeeze(1).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         model0.eval()\n",
    "#         for i, input in enumerate(validation_fp):\n",
    "#             output = model(input)\n",
    "#             scores.update({round(output.item(), 3): validation_smiles[i]})\n",
    "#             # scores.append(output.item())\n",
    "#         return scores\n",
    "\n",
    "# print(evaluate_smiles(model0, validation_smiles))\n",
    "\n",
    "\n",
    "# # print(f\"Prediction for {validation_smiles}: {prediction:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honours",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
